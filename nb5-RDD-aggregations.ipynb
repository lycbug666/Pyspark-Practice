{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can aggregate RDD data in Spark by using three different actions: reduce, fold, and aggregate. The last one is the more general one and someway includes the first two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = \"file:///home/lygbug666/workdir/spark-py-notebooks/kddcup.data_10_percent.gz\"\n",
    "raw_data = sc.textFile(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting interaction duration by tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fold操作有初始参数供第一次调用，reduce操作则没有。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = raw_data.map(lambda x: x.split(\",\"))\n",
    "\n",
    "normal_csv_data = csv_data.filter(lambda x: x[41]==\"normal.\")\n",
    "attack_csv_data = csv_data.filter(lambda x: x[41]!=\"normal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that we pass to reduce gets and returns elements of the same type of the RDD. If we want to sum durations we need to extract that element into a new RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add time together, change str to int \n",
    "\n",
    "normal_duration_data = normal_csv_data.map(lambda x: int(x[0]))\n",
    "attack_duration_data = attack_csv_data.map(lambda x: int(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration for 'normal' interactions is 21075991\n",
      "Total duration for 'attack' interactions is 2626792\n"
     ]
    }
   ],
   "source": [
    "total_normal_duration = normal_duration_data.reduce(lambda x, y: x + y)\n",
    "total_attack_duration = attack_duration_data.reduce(lambda x, y: x + y)\n",
    "\n",
    "print (\"Total duration for 'normal' interactions is {}\".\\\n",
    "    format(total_normal_duration))\n",
    "print (\"Total duration for 'attack' interactions is {}\".\\\n",
    "    format(total_attack_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean duration for 'normal' interactions is 216.657\n",
      "Mean duration for 'attack' interactions is 6.621\n"
     ]
    }
   ],
   "source": [
    "normal_count = normal_duration_data.count()\n",
    "attack_count = attack_duration_data.count()\n",
    "\n",
    "print (\"Mean duration for 'normal' interactions is {}\".\\\n",
    "    format(round(total_normal_duration/float(normal_count),3)))\n",
    "print (\"Mean duration for 'attack' interactions is {}\".\\\n",
    "    format(round(total_attack_duration/float(attack_count),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a first (and too simplistic) approach to identify attack interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A better way, using aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregate action frees us from the constraint of having the return be the same type as the RDD we are working on. \n",
    "Like with fold, we supply an initial zero value of the type we want to return. \n",
    "We provide two functions. The first one is used to combine the elements from our RDD with the accumulator. \n",
    "The second function is needed to merge two accumulators. \n",
    "Let's see it in action calculating the mean we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_data = raw_data.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean duration for 'normal' interactions is 216.657\n"
     ]
    }
   ],
   "source": [
    "normal_sum_count = normal_duration_data.aggregate(\n",
    "    (0,0), # initial value\n",
    "    (lambda acc, value: (acc[0]+value, acc[1]+1)), # combine value with acc[0], kind of value with acc[1]\n",
    "    (lambda acc1, acc2: (acc1[0]+acc2[0], acc1[1]+acc2[1]))) # reduce accumulators\n",
    "\n",
    "print (\"Mean duration for 'normal' interactions is {}\".\\\n",
    "    format(round(normal_sum_count[0]/float(normal_sum_count[1]),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean duration for 'attack' interaction is 6.621\n"
     ]
    }
   ],
   "source": [
    "attack_sum_count = attack_duration_data.aggregate(\n",
    "    (0,0),\n",
    "    (lambda acc, value:(acc[0]+value, acc[1]+1)),\n",
    "    (lambda acc1,acc2: (acc1[0]+acc2[0], acc1[1]+acc2[1])))\n",
    "\n",
    "print (\"Mean duration for 'attack' interaction is {}\" .\\\n",
    "      format(round(attack_sum_count[0]/float(attack_sum_count[1]),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous aggregation, the accumulator first element keeps the total sum, while the second element keeps the count. Combining an accumulator with an RDD element consists in summing up the value and incrementing the count. Combining two accumulators requires just a pairwise sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 4)\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3,4],3).aggregate((1,0),\n",
    "    (lambda acc, value:(acc[0]+value, acc[1]+1)),\n",
    "    (lambda acc1,acc2: (acc1[0]+acc2[0], acc1[1]+acc2[1])))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ sum of RDD elements + acc initial value * No. of RDD partitions + acc initial value ]\n",
    "if not defined the number of partitions is 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
